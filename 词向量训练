
'''

import gensim
import os

class MySentences(object):
    def __init__(self, dirname):
        self.dirname = dirname

    def __iter__(self):
        for fname in os.listdir(self.dirname):
            for line in open(os.path.join(self.dirname, fname)):
                yield line.split()


sentences = MySentences('/some/directory')  # a memory-friendly iterator
model = gensim.models.Word2Vec(sentences)


word1='物流系统'
word2='信息系统'
from gensim.models import word2vec

sentences = word2vec.Text8Corpus('idf.txt')

model = word2vec.Word2Vec(sentences)



with open('dic.txt','r+',encoding='UTF-8') as foo:
    for line in foo.readlines():
        if word1 in line:
            continue
    else:
        foo.write(word1)
        foo.write(' ')

with open('dic.txt','r+',encoding='UTF-8') as foo:
    for line in foo.readlines():
        if word2 in line:
            continue
    else:
        foo.write(word2)
        foo.write(' ')

sim=model.similarity(word1,word2)
print(sim)

'''
import numpy as np
from gensim.models import word2vec

# 加载语料
sentences = word2vec.Text8Corpus('dict.txt')

# 训练模型
model = word2vec.Word2Vec(sentences,min_count = 1)

# 选出最相似的10个词
v1=np.array(model['物流'])
v2=np.array(model['信息'])

#score=np.linalg.norm(v1-v2)
#print(score)

distance=np.dot(v1,v2)
print(v1)
print(v2)
print(np.dot(v1,v2))